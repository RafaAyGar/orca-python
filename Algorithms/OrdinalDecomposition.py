
from sys import exit
import numpy as np

from sklearn.metrics.scorer import make_scorer

from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.utils.validation import check_X_y, check_array, check_is_fitted


class OrdinalDecomposition(BaseEstimator, ClassifierMixin):

	"""
	OrdinalDecomposition ensemble classifier

	This class implements an ensemble method, where an ordinal problem is 
	decomposed into several binary subproblems, each one of which will
	generate a different model, though all will share same inner classifier
	and parameters for it.

	There are 4 different ways to decompose the original problem based on 
	how the coding matrix is built.


	Parameters
	----------

	dtype: string
		Type of decomposition to be performed by class. May be one of 4 different
		types: 'OrderedPartitions', 'OneVsNext', 'OneVsFollowers' or 'OneVsPrevious'

		The coding matrix generated by each method, for a problem with 5 classes
		will be as follows:

		OrderedPartitions	 OneVsNext		OneVsFollowers		OneVsPrevious
		
			-, -, -, -;		-,  ,  ,  ;		  -,  ,  ,  ;		  +, +, +, +;
			+, -, -, -;		+, -,  ,  ;		  +, -,  ,  ;		  +, +, +, -;
			+, +, -, -;		 , +, -,  ;		  +, +, -,  ;		  +, +, -,  ;
			+, +, +, -;		 ,  , +, -;		  +, +, +, -;		  +, -,  ,  ;
			+, +, +, +;		 ,  ,  , +;		  +, +, +, +;		  -,  ,  ,  ;

		where rows represents classes and columns classifiers. plus signs indicate
		that for that classifier, that class will be part of the positive class,
		on the other hand, a minus sign places that class into the the negative one
		for that binary problem. If there is no sign, then those samples will not be
		taken into account when building the model.

	algorithm: string
		Inner classifier to be used to build a model for each binary subproblem.
		It has to call a local classifier build into this framework, or else a
		method from scikit-learn.

	parameters: dict
		This dictionary will contain the parameters which the classifier will be
		built with. Because cross-validation for this meta-classifer is built
		outside, only one value it's allowed for each parameter.


	Attributes
	----------

	unique_y_: list
		List that contains all different class labels found in original dataset


	coding_matrix_: array-like, shape (n_targets, n_targets-1)
		Matrix that defines which classes use when building each subproblem, 
		and in which binary class they belong inside those new models.

		Further explained previously.

	classifiers_: list of classifiers
		Initialy empty, will include all fitted models for each subproblem
		once the fit function for this class is called successfully.


	Examples
	--------

	see LogisticRegression source code for an example


	References
	----------



	"""

	def __init__(self, dtype="", algorithm="",  parameters={}):

		self.dtype = dtype
		self.algorithm = algorithm
		self.parameters = parameters


	def fit(self, X, y):

		"""
		Fit the model according to the given training data

		Parameters
		----------

		X: {arra-like, sparse matrix}, shape (n_samples, n_features)
			Training vector, where n_samples is the number of samples and
			n_features is the number of features

		y: array-like, shape (n_samples)
			Target vector relative to X

		Returns
		-------

		self: object
		"""


		X, y = check_X_y(X, y)

		self.X_ = X
		self.y_ = y

		# Get list of different targets of dataset
		self.unique_y_ = np.unique(y)

		# Gives each train input its corresponding output label for each binary classifier
		self.coding_matrix_ = self._codingMatrix( len(self.unique_y_), self.dtype )
		class_labels = self.coding_matrix_[ (np.digitize(y, self.unique_y_) - 1), :]


		self.classifiers_ = []
		# Fitting n_targets-1 classifiers, each one with a different combination of train inputs
		# given by the coding_matrix
		for n in range(len(class_labels[0,:])):

			estimator = self._loadAlgorithm().fit(	X[ np.where(class_labels[:,n] != 0) ], \
													np.ravel(class_labels[np.where(class_labels[:,n] != 0), n].T) )
			self.classifiers_.append(estimator)


		return self


	def predict(self, X):

		"""

		Parameters
		----------


		Returns
		-------

		"""

		# Check is fit had been called
		check_is_fitted(self, ['X_', 'y_'])

		# Input validation
		X = check_array(X)


		#TODO: Cual es la clase positiva ??
		positive_class = -1
		predictions = np.array([np.interp( np.ravel(c.predict_proba(X)[:, np.where(c.classes_ == positive_class) ]), (0, 1), (-1, +1) )\
								for c in self.classifiers_]).T
		#predictions = np.array([np.interp( c.predict_proba(X)[:,0], (0, 1), (-1, +1) ) for c in self.classifiers_]).T

		eLosses = np.zeros( (X.shape[0], self.coding_matrix_.shape[0]) )

		for i in range(self.coding_matrix_.shape[0]):

			eLosses[:,i] = np.sum(np.exp( predictions * np.tile(self.coding_matrix_[i,:], (predictions.shape[0], 1)) ), axis=1)

		predicted_y = self.unique_y_[np.argmin(eLosses, axis=1)]
		return predicted_y


	def _loadAlgorithm(self):

		"""

		Loads and return a classifier.

		Arguments for this function are received globally from class's constructor
		The ones used here ara 'algorithm' and 'parameters'

		Returns
		-------

		algorithm: object
			Returns a loaded classifier, either from an scikit-learn module, or from
			a module of this framework.

		"""

		# Loading modules to execute algorithm given in configuration file
		modules = [x for x in self.algorithm.split('.')]

		if (len(modules) == 1):
			algorithm = __import__(modules[0])
			algorithm = getattr(algorithm, modules[0])

		elif (len(modules) == 3):
			algorithm = __import__(modules[0] + '.' + modules[1], fromlist=[str(modules[2])])
			algorithm = getattr(algorithm, modules[2])

		else:
			pass

		algorithm = algorithm(**self.parameters)
		return algorithm



	def _codingMatrix(self, nClasses, dType):

		"""
			Method that returns the coding matrix for a given dataset.

			Parameters
			----------
 
			nClasses: int
				Number of different classes in actual dataset
			
			dType: string
				Type of decomposition to be applied

			Returns
			-------

			Coding Matrix: array-like, shape (n_targets, n_targets-1)
				Each value must be in range {-1, 1, 0}, whether that class will belong
				to negative class, positive class or will not be used for that particular
				binary classifier.
		"""

		dType = dType.lower()

		if dType == "orderedpartitions":

			coding_matrix = np.triu( (-2 * np.ones(nClasses - 1)) ) + 1
			coding_matrix = np.vstack([coding_matrix, np.ones((1, nClasses-1))])

		elif dType == "onevsnext":

			plus_ones = np.diagflat(np.ones((1, nClasses - 1), dtype=int), -1)
			minus_ones = -( np.eye(nClasses, nClasses - 1, dtype=int) )
			coding_matrix = minus_ones + plus_ones[:,:-1]

		elif dType == "onevsfollowers":

			minus_ones = np.diagflat(-np.ones((1, nClasses), dtype=int))
			plus_ones = np.tril(np.ones(nClasses), -1)
			coding_matrix = (plus_ones + minus_ones)[:,:-1]

		elif dType == "onevsprevious":

			plusones = np.triu(np.ones(nClasses))
			minusones = -np.diagflat(np.ones((1, nClasses - 1)), -1)
			coding_matrix = np.flip( (plusones + minusones)[:,:-1], axis=1 )

		else:

			print "Decomposition type", dType, "does not exist."
			#exit()

		return coding_matrix.astype(int)


	"""
	def predict(self, X):

		X = check_array(X)

		# Outputs predicted to given data by fitted model
		predicted_proba_y = np.empty( [X.shape[0], len(self.classifiers_) + 1] )

		for i, c in enumerate(self.classifiers_):

			if i == 0:
				predicted_proba_y[:,i] = 1 - c.predict_proba(X)[:,0]
			else:
				predicted_proba_y[:,i] = previous_proba_y - c.predict_proba(X)[:,0]

			# Storing actual prediction for next iteration
			previous_proba_y = c.predict_proba(X)[:,1]

		predicted_proba_y[:,-1] = self.classifiers_[-1].predict_proba(X)[:,0]
		predicted_y = np.argmax(predicted_proba_y, axis=1)

		return predicted_y
	"""






